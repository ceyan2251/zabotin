import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns
from IPython.core.pylabtools import figsize
#ignore warnings
import warnings
warnings.filterwarnings('ignore')
figsize(40,20)

url = 'https://drive.google.com/u/0/uc?id=1-TzMGAKLjS9RrYXSBWCAD0zAk-gd1pab&export=download'
data = pd.read_csv(url)
data.info()
Все значения признаков ненулевые, Как и в прошлый раз проверим на наличие дубликатов:
Имеется 240 дублей, несчадно убиваем их т.к. будут мешать учиться\
print('Строк до: ', len(data))
data.drop_duplicates(keep='first', inplace=True)
print('Строк после: ',len(data))
Разделим данные для обучения и проверки
X_columns = data.columns[:-1]
y_column = data.columns[-1]
X = data[X_columns]
y = data[y_column]

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y)
Почистим от коррелирующих признаков
X_train.drop(['citric acid', 'density', 'pH', 'total sulfur dioxide'], axis = 'columns', inplace=True)
X_test.drop(['citric acid', 'density', 'pH', 'total sulfur dioxide'], axis = 'columns', inplace=True)
X_columns = X_train.columns[:-1]
Распределение признаков
sns.countplot(X_train['chlorides'], hue=y_train)
data_for_pairgrid = X_train[X_columns]
data_for_pairgrid[y_column] = y_train

sns.PairGrid(data_for_pairgrid, hue=y_column).map(plt.scatter)\
рассмотрим возможные выбросы
g = sns.PairGrid(data, x_vars=X_columns, y_vars=[y_column],
            height=5.)

for irow, icol in np.ndindex(g.axes.shape):
    ax = g.axes[irow][icol]
    sns.boxplot(x=X_columns[icol], y=[y_column][irow], hue=[y_column][irow],
                dodge=False,
                data=data,
                orient="h",
                ax=ax)
 Плотности распределения величин
 g = sns.PairGrid(data, x_vars=X_columns, y_vars=[y_column],
            height=5.)

for irow, icol in np.ndindex(g.axes.shape):
    ax = g.axes[irow][icol]
    sns.violinplot(x=X_columns[icol], y=[y_column][irow], hue=[y_column][irow],
                dodge=False,
                data=data,
                orient="h",
                ax=ax)
Нормализация
from sklearn.preprocessing import MinMaxScaler
from sklearn.neighbors import KNeighborsClassifier

print("Качество алгоритма до нормализации: ", KNeighborsClassifier(n_neighbors=2).fit(X_train,y_train).score(X_test,y_test))
scaler = MinMaxScaler()
X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train),columns=X_train.columns)
X_test_scaled = pd.DataFrame(scaler.fit_transform(X_test),columns=X_test.columns)

print("Качество алгоритма после нормализации: ", KNeighborsClassifier(n_neighbors=2).fit(X_train_scaled,y_train).score(X_test_scaled,y_test))

figsize(15,10)
fig, (ax1,ax2) = plt.subplots(ncols=2)
ax1.set_title('До нормализации')
sns.kdeplot(X_train['alcohol'], ax=ax1)
sns.kdeplot(X_train['sulphates'], ax=ax1)

ax2.set_title('После нормализации MinMax')
sns.kdeplot(X_train_scaled['alcohol'], ax=ax2)
sns.kdeplot(X_train_scaled['sulphates'], ax=ax2)

plt.show()
Стратификация
plt.style.use('fivethirtyeight')
plt.hist(y_train, bins=100)
plt.xlabel('quality')
plt.ylabel('rows')
plt.title('Quality distribution')
Имеется дисбаланс, применяем оверсемплинг
from imblearn.over_sampling import SMOTE

smote = SMOTE()
X_sm, y_sm = smote.fit_resample(X, y)
X_train_sm, X_test_sm, y_train_sm, y_test_sm = train_test_split(X_sm,y_sm)
plt.hist(y_train_sm, bins=100)
plt.xlabel('quality')
plt.ylabel('rows')
plt.title('Quality distribution after oversampling')
подбор алгоритма
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import SGDClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB

for clf in [DecisionTreeClassifier(), SGDClassifier(), SVC(), GaussianNB(), KNeighborsClassifier()]:
  print(clf.__class__.__name__, clf.fit(X_train_scaled, y_train).score(X_test_scaled, y_test))
  for clf in [DecisionTreeClassifier(), SGDClassifier(), SVC(), GaussianNB(), KNeighborsClassifier()]:
  print(clf.__class__.__name__, clf.fit(X_train_sm, y_train_sm).score(X_test_sm, y_test_sm))
  X_train_sm_scaled = pd.DataFrame(scaler.fit_transform(X_train_sm),columns=X_columns)
X_test_sm_scaled = pd.DataFrame(scaler.fit_transform(X_test_sm),columns=X_columns)

for clf in [DecisionTreeClassifier(), SGDClassifier(), SVC(), GaussianNB(), KNeighborsClassifier()]:
  print(clf.__class__.__name__, clf.fit(X_train_sm_scaled, y_train_sm).score(X_test_sm_scaled, y_test_sm))
  
